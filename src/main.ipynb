{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting\n",
    "PROMPT_STYLE = 'AutoCOT1'\n",
    "data_count = 10\n",
    "examle_count = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "import config \n",
    "\n",
    "BASE_PROMPT_FILE_PATH = f'./base_prompt/{PROMPT_STYLE}.txt'\n",
    "PROMPT_FILE_PATH = config.PROMPT_PATH + f'{PROMPT_STYLE}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run generator.js\n",
    "import subprocess\n",
    "\n",
    "params = [\"200\", \"200\"] # Enter the number of data. each prameter indicate the number of small, large map.\n",
    "\n",
    "subprocess.run([\"node\", \"generator.js\"] + params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run placer.py\n",
    "import placer\n",
    "\n",
    "maps = placer.load_maps()\n",
    "for map in maps:\n",
    "    placer.assign_parameters(map, enemy_density=0.05, cohesion=0.3, treasure_density=0.01, range_multiplier=2, boss=True)\n",
    "    placer.modify_map(map, group_min_dist=10, flag_try_count=50, enemy_sparsity=3)\n",
    "placer.save_maps(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run labeler.py\n",
    "import labeler\n",
    "\n",
    "labeler.label(placed_file_path=config.PLACED_PATH, labelled_file_path=config.LABELED_PATH, file_count=4, difficulty_curve_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate preprocessed\n",
    "from preprocessed_data_generator import preprocessed_data_generator\n",
    "\n",
    "preprocessed_data_generator(data_count, examle_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparator.py\n",
    "import comparator\n",
    "\n",
    "comparator.compare(preprocessed_path=config.PREPROCESSED_PATH, compared_path=config.COMPARED_PATH, file_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get compared file\n",
    "import os\n",
    "import json\n",
    "\n",
    "path = os.path.join(config.COMPARED_PATH)\n",
    "\n",
    "filename_list = [\n",
    "    filename\n",
    "    for filename in os.listdir(path)\n",
    "    if filename.endswith(\".json\") and os.path.isfile(os.path.join(path, filename))\n",
    "]\n",
    "\n",
    "path_list = [os.path.join(path, filename) for filename in filename_list]\n",
    "\n",
    "compared_list = list()\n",
    "for file_path in path_list:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        compared_batch = json.load(file)\n",
    "        for compared in compared_batch[\"map_list\"]:\n",
    "            compared_list.append(compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference\n",
    "diff_dict = dict()\n",
    "\n",
    "params = [\n",
    "    \"map_size\",\n",
    "    \"room_count\",\n",
    "    \"enemy_count\",\n",
    "    \"treasure_count\"\n",
    "]\n",
    "\n",
    "for param in params:\n",
    "    diff_dict[param] = list()\n",
    "\n",
    "for compared in compared_list:\n",
    "    for param in params:\n",
    "        try:\n",
    "            diff_dict[param].append([abs(float(compared[\"after_params\"][param][i]) - float(compared[\"before_params\"][param][i])) for i in range(len(compared[\"after_params\"][param]))])\n",
    "        except:\n",
    "            diff_dict[param].append(abs(float(compared[\"after_params\"][param]) - float(compared[\"before_params\"][param])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation\n",
    "import numpy as np\n",
    "\n",
    "mean_dict = dict()\n",
    "std_dict = dict()\n",
    "\n",
    "for param in params:\n",
    "    try:\n",
    "        mean_dict[param] = np.mean(np.array(diff_dict[param]), axis=0)\n",
    "        std_dict[param] = np.std(np.array(diff_dict[param]), axis=0)\n",
    "    except:\n",
    "        mean_dict[param] = np.mean(diff_dict[param])\n",
    "        std_dict[param] = np.std(diff_dict[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean and standard deviation\n",
    "print(mean_dict)\n",
    "print(std_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate playability\n",
    "\n",
    "playability_list = list()\n",
    "for i in range(len(compared_list)):\n",
    "    playability_list.append(compared_list[i][\"after_params\"][\"playability\"])\n",
    "\n",
    "playability_mean = np.mean(playability_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print playability\n",
    "print(playability_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ugrp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
